# Database
DATABASE_URL="postgresql://postgres:postgres@localhost:5432/screenshare"

# Server
PORT=3001
CORS_ORIGIN="http://localhost:3000"

# Logging
# Levels: trace, debug, info, warn, error, fatal
LOG_LEVEL="debug"

# ============================================================================
# AI PROVIDER CONFIGURATION
# ============================================================================
#
# Vision and TTS are configured independently:
#
#   VISION_PROVIDER  →  "azure" (default, GPT-5.2) or "anthropic" (Claude)
#   TTS_PROVIDER     →  "elevenlabs" (default) or "azure" (Azure Speech)
# ============================================================================

VISION_PROVIDER="azure"       # "azure" (default) or "anthropic"
TTS_PROVIDER="elevenlabs"     # "elevenlabs" (default) or "azure"

# ============================================================================
# AZURE OPENAI - Required when VISION_PROVIDER=azure (default)
# ============================================================================

AZURE_OPENAI_ENDPOINT="https://your-resource.cognitiveservices.azure.com"
AZURE_OPENAI_API_KEY=""
AZURE_OPENAI_DEPLOYMENT_VISION="gpt-5.2"  # default

# ============================================================================
# ELEVENLABS (Text-to-Speech) - Required when TTS_PROVIDER=elevenlabs (default)
# ============================================================================

ELEVENLABS_API_KEY=""
ELEVENLABS_VOICE_ID="21m00Tcm4TlvDq8ikWAM"  # Rachel (default)
ELEVENLABS_MODEL_ID="eleven_turbo_v2_5"      # ElevenLabs TTS model

# ============================================================================
# ANTHROPIC (Claude) - Only needed if VISION_PROVIDER=anthropic
# ============================================================================

# ANTHROPIC_API_KEY="sk-ant-..."

# ============================================================================
# AZURE SPEECH (Text-to-Speech) - Required when TTS_PROVIDER=azure
# ============================================================================

# Azure Speech endpoint (e.g., https://eastus.tts.speech.microsoft.com)
AZURE_SPEECH_ENDPOINT=""

# Azure Speech API key
AZURE_SPEECH_API_KEY=""

# Voice name (default: en-US-JennyNeural)
AZURE_SPEECH_VOICE_NAME="en-US-JennyNeural"

# ============================================================================
# AZURE BLOB STORAGE (Recording Storage)
# ============================================================================

# Connection string from Azure Portal → Storage Account → Access Keys
AZURE_STORAGE_CONNECTION_STRING="DefaultEndpointsProtocol=https;AccountName=...;AccountKey=...;EndpointSuffix=core.windows.net"

# Container name for storing recordings and frames
AZURE_STORAGE_CONTAINER_NAME="screenshare-recordings"

# ============================================================================
# FRONTEND (prefix with NEXT_PUBLIC_)
# ============================================================================

NEXT_PUBLIC_API_URL="http://localhost:3001"
NEXT_PUBLIC_WS_URL="ws://localhost:3001"
